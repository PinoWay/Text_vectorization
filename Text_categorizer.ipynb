{"cells":[{"cell_type":"markdown","id":"3fc2cf5e","metadata":{"id":"3fc2cf5e"},"source":["\n","## Цели работы\n","\n","- Попрактиковаться в предобработке текстовых данных (токенизация, лемматизация, векторизация).\n","\n","- Построить две модели классификации с разными способами векторизации текстов (`CountVectorizer` и `TfIdfVectorizer`).\n","- Сравнить качество моделей.\n","\n","## Что нужно сделать\n","\n","1. Загрузите датасет из файла, приложенного к заданию (`m18_jokes_dataset.csv`).\n","\n","1. Закодируйте целевую переменную с помощью `LabelEncoder`.\n","1. Разделите выборку на тренировочную и тестовую.\n","1. Используя знания из модуля, подготовьте функцию `preprocess`, которая:\n","- удаляет стоп-слова в соответствии со списком `nltk.corpus.stopwords`;\n","- приводит слова к нормальной форме с помощью `pymorphy2`.\n","5. Создайте экзепляры векторизаторов `CountVectorizer` и `TfIdfVectorizer`. В качестве функции предобработки данных оба должны использовать функцию `preprocess`.\n","\n","1. Векторизуйте признаки тренировочной и тестовой выборок. Сохраните результаты `CountVectorizer` в `X_train_count` и `X_test_count`, а результаты `TfIdfVectorizer` – в `X_train_tfidf` и `X_test_tfidf`.\n","1. Обучите две модели классификации, например `LinearSVC`.\n","1. Оцените работу обеих моделей на тестовой выборке, используя `f1_score` с методом усреднения `macro` (параметр `average='macro'`) – это арифметическое среднее f1-метрик, рассчитанных для каждого класса.\n","\n","## Информация о задаче\n","\n","### Описание датасета\n","\n","`m18_jokes_dataset.csv` – датасет, подготовленный на основе датасета, размещённого [на kaggle](https://www.kaggle.com/datasets/konstantinalbul/russian-jokes). Наш датасет содержит две колонки:\n","\n","- **text** — текст анекдота (скорее всего, несмешного, но ваша задача не смеяться, а решить задачу классификации);\n","\n","- **theme** — категория, к которой относится шутка.\n","\n","Датасет содержит данные для задачи многоклассовой классификации. В отличие от оригинального датасета, в нашем классов меньше, зато они идеально сбалансированы: в каждом ровно тысяча примеров. Так вам будет проще сконцентрироваться на текстовых данных."]},{"cell_type":"code","execution_count":1,"id":"iWLwXf7c-k2d","metadata":{"executionInfo":{"elapsed":32489,"status":"ok","timestamp":1692162712639,"user":{"displayName":"Way Morales","userId":"07534500700542411887"},"user_tz":-300},"id":"iWLwXf7c-k2d"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"markdown","id":"eNU49CstvoV_","metadata":{"id":"eNU49CstvoV_"},"source":["### Импорт нужных библиотек"]},{"cell_type":"code","execution_count":2,"id":"398d32d2","metadata":{"executionInfo":{"elapsed":2635,"status":"ok","timestamp":1692162731452,"user":{"displayName":"Way Morales","userId":"07534500700542411887"},"user_tz":-300},"id":"398d32d2"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer\n","import pymorphy2\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","id":"Tc7cGASwvr83","metadata":{"id":"Tc7cGASwvr83"},"source":["### Загрузка данных"]},{"cell_type":"code","execution_count":3,"id":"gPGgRGWcCHwB","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1176,"status":"ok","timestamp":1692162735562,"user":{"displayName":"Way Morales","userId":"07534500700542411887"},"user_tz":-300},"id":"gPGgRGWcCHwB","outputId":"48bced4b-6fb1-4656-b87e-28ccc5b5f9de"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>theme</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>aforizmi</td>\n","      <td>Почему удар в спину наносят те, кого,как прави...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>aforizmi</td>\n","      <td>Музы - пожалуй самые мудрые представительницы...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>aforizmi</td>\n","      <td>Тяжело бухать всю ночь, особенно если ночь пол...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>aforizmi</td>\n","      <td>ПОКУШЕНИЕ. НАЛИЧНОСТЬ.\\r\\n\\r\\n\\r\\n</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>aforizmi</td>\n","      <td>Когда медленно танцуешь, ничего не мешает...\\r...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      theme                                               text\n","0  aforizmi  Почему удар в спину наносят те, кого,как прави...\n","1  aforizmi  Музы - пожалуй самые мудрые представительницы...\n","2  aforizmi  Тяжело бухать всю ночь, особенно если ночь пол...\n","3  aforizmi                 ПОКУШЕНИЕ. НАЛИЧНОСТЬ.\\r\\n\\r\\n\\r\\n\n","4  aforizmi  Когда медленно танцуешь, ничего не мешает...\\r..."]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(f'data/jokes_dataset.csv')\n","data.head()"]},{"cell_type":"code","execution_count":4,"id":"ex3ja6y9EHZ6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692156085608,"user":{"displayName":"Way Morales","userId":"07534500700542411887"},"user_tz":-300},"id":"ex3ja6y9EHZ6","outputId":"e0ccd95a-f024-44dd-ca9c-885822b294fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Соотношение классов в процентах:\n"]},{"data":{"text/plain":["aforizmi                 5.882353\n","pro-mugchin              5.882353\n","shkolnie-i-pro-shkolu    5.882353\n","raznie                   5.882353\n","pro-vovochku             5.882353\n","pro-studentov            5.882353\n","pro-semyu                5.882353\n","pro-novih-russkih        5.882353\n","pro-militsiyu            5.882353\n","meditsinskie             5.882353\n","pro-evreev               5.882353\n","pro-detey                5.882353\n","pro-armiu                5.882353\n","pro-alkogolikov          5.882353\n","poshlie-i-intimnie       5.882353\n","narodnie                 5.882353\n","tsitati                  5.882353\n","Name: theme, dtype: float64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["print('Соотношение классов в процентах:')\n","data.theme.value_counts()/len(data)*100"]},{"cell_type":"markdown","id":"vE1WMJ51vx6F","metadata":{"id":"vE1WMJ51vx6F"},"source":["### Подготовка данных для обучения"]},{"cell_type":"code","execution_count":5,"id":"T-bjtvA1D8tB","metadata":{"id":"T-bjtvA1D8tB"},"outputs":[],"source":["le = LabelEncoder()\n","data['theme'] = le.fit_transform(data['theme'])"]},{"cell_type":"code","execution_count":6,"id":"S6wOOuQrEYt2","metadata":{"id":"S6wOOuQrEYt2"},"outputs":[],"source":["X = data.text\n","y = data.theme\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]},{"cell_type":"code","execution_count":7,"id":"_u5I9FDeE4Fm","metadata":{"id":"_u5I9FDeE4Fm"},"outputs":[],"source":["def preprocess(text):\n","    lemm_words = []\n","    tokenizer = RegexpTokenizer('\\w+')\n","    stop_words = stopwords.words('russian')\n","    morph = pymorphy2.MorphAnalyzer()\n","    for word in tokenizer.tokenize(text):\n","        word = word.lower()\n","        if word not in stop_words:\n","            lemm_words.append(morph.parse(word)[0].normal_form)\n","    return ' '.join(lemm_words)"]},{"cell_type":"code","execution_count":8,"id":"gSotZaLqGOWX","metadata":{"id":"gSotZaLqGOWX"},"outputs":[],"source":["count_vectorizer = CountVectorizer(preprocessor=preprocess)\n","count_vectorizer.fit(X_train)\n","X_train_count = count_vectorizer.transform(X_train)\n","X_test_count = count_vectorizer.transform(X_test)"]},{"cell_type":"code","execution_count":9,"id":"s2uJK5GpG1kf","metadata":{"id":"s2uJK5GpG1kf"},"outputs":[],"source":["tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocess)\n","tfidf_vectorizer.fit(X_train)\n","X_train_tfidf = tfidf_vectorizer.transform(X_train)\n","X_test_tfidf = tfidf_vectorizer.transform(X_test)"]},{"cell_type":"markdown","id":"275RSFW1v3WV","metadata":{"id":"275RSFW1v3WV"},"source":["### Создание и обучение моеделей LinearSVC"]},{"cell_type":"code","execution_count":10,"id":"a4WinP1tHNli","metadata":{"id":"a4WinP1tHNli"},"outputs":[],"source":["model_count = LinearSVC(max_iter=10000)\n","model_count.fit(X_train_count, y_train)\n","y_pred_count = model_count.predict(X_test_count)\n","score_count = f1_score(y_test, y_pred_count, average='macro')\n","\n","model_tfidf = LinearSVC(max_iter=10000)\n","model_tfidf.fit(X_train_tfidf, y_train)\n","y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n","score_tfidf = f1_score(y_test, y_pred_tfidf, average='macro')"]},{"cell_type":"markdown","id":"EEaDZA1mv8CF","metadata":{"id":"EEaDZA1mv8CF"},"source":["### Вывод метрик"]},{"cell_type":"code","execution_count":11,"id":"k9kPrgsBt0gS","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1692162363958,"user":{"displayName":"Way Morales","userId":"07534500700542411887"},"user_tz":-300},"id":"k9kPrgsBt0gS","outputId":"f4dd4e14-ea9f-4888-e762-eb8b5c91c5b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["f1_score при использовании Count_Vectorizer: 0.5996109085990549\n","f1_score при использовании Tfidf_Vectorizer: 0.6275222883803963\n"]}],"source":["print(f'f1_score при использовании Count_Vectorizer: {score_count}')\n","print(f'f1_score при использовании Tfidf_Vectorizer: {score_tfidf}')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":5}
